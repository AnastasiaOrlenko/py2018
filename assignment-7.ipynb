{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание работы\n",
    "\n",
    "Ячейки 2,14 - чтение списка имен и подготовка словарей.\n",
    "\n",
    "14 - Выделение учебного и тестового списков.\n",
    "\n",
    "30 - Модель RNN.\n",
    "\n",
    "224 - Функции обучения, проверки и генерации.\n",
    "\n",
    "224 - Функция вычисления перплексии. Под перплексией здесь понимается, по определению, экспонента от энтропии. Но в данном случае она вычисляется отдельно для каждой строки по sofmax-вероятности модели для тестовой выборки. Также она усредняется по всем именам тестовой выборки, т.е. делится на число батчей и размер батча. Потому что в противном случае перплексия возрастала бы с увеличением тестовой выборки.\n",
    "\n",
    "6 - Формирование итератора батчей.\n",
    "\n",
    "229 - Задание параметров.\n",
    "\n",
    "230  - Цикл по эпохам.\n",
    "\n",
    "28 - Генерация имен по начальным буквам. Используется температура softmax = 0.1.\n",
    "\n",
    "## Результаты\n",
    " * Сеть построена и обучена. Loss для учебной и тестовой выборки одинаков, т.к. обучение без учителя. Поэтому ранний останов невозможен.\n",
    " * Для генерации выбрана длина последовательности и начальный токен - заглавная буква.\n",
    " * Примеры сгенерированных имен поражают своей лаконичной креативностью. Особенно понравились: Crape, Insanity, Desthene, Eesinifemin.\n",
    " * Среди других особенностей модели: однообразная (при temp=1.0) привязанность к зонтам, имена: Sont,\n",
    "Yond, Zont.\n",
    " * Эксперименты с размером внутреннего состояния, размером батча и эмбеддинга, слоями. Намечены, но не проведены до конца. Размер батча влияет на результаты: меньше - лучше.\n",
    " * Неудачен подход с фиксированной длиной строки в 30 символов. Слишком много пробелов и модель учится делать только короткие однословные названия. Следует переделать модель, введя начальный и завершающий токены < BOS >, < EOS >. Как вариант, использовать RNN-ячейки, варьируя длину цепочки для каждого батча и собирая в него имена одинаковой длины. Полученные имена слишком короткие. Однако задача получения качественных имен не ставилась.\n",
    " * График перплексии отличается от графика потерь, хотя тенденция уменьшения перплексии заметна, достаточно хорошие результаты получаются на первых 10-20 эпохах. Вероятно, что это связано с простотой задачи и небольшой выборкой. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "\n",
    "Assignment 7.\n",
    "Delelop language model, which generates death metal band names.\n",
    "You can get data from https://www.kaggle.com/zhangjuefei/death-metal.\n",
    "You are free to use any other data, but the most easy way is just to take the band name column. \n",
    "Your language model should be char-based autogression RNN.\n",
    "Text generation should be terminated when either max length is reached or terminal symbol is generated.\n",
    "\n",
    "Different band names can be generated by:\n",
    " - init $h_0$ as random vector from some probabilty distribution.\n",
    " - sampling over tokens at each timestep with probability = softmax\n",
    "\n",
    "Calculate perplexity for your model = your objective quality metric.\n",
    "Also, sample 10 band names from your model for subjective evaluation. E.g. names like 'qwiouefiou23riop2h3' or 'death death death!' are bad examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=\"pt.log\", level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37723,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bands.csv')\n",
    "dn = shuffle(df['name'])\n",
    "dn.to_csv('names.csv', index=False)\n",
    "bb = dn.tolist()\n",
    "dn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37723 678 37723 37045 80 48 1.7973119847308008\n",
      "48 11.1772438925631 4.476794041050821\n",
      "80\n",
      "29636\n",
      "29636 7409\n"
     ]
    }
   ],
   "source": [
    "# Удалены русские, китайские и другие не ascii имена - всего 1.8%\n",
    "i = 0\n",
    "k = 0\n",
    "bc = []\n",
    "s = set()\n",
    "max = 0\n",
    "mm = []\n",
    "for b in bb:\n",
    "    i += 1\n",
    "    benc = b.encode('ascii', 'ignore').decode('utf8')\n",
    "    if benc != b:\n",
    "        k += 1\n",
    "        #print(b, '=', benc)    \n",
    "        continue\n",
    "    bc.append(b)\n",
    "    s |= set(b)\n",
    "    lena = len(b)\n",
    "    mm.append(lena)\n",
    "    if lena > max:\n",
    "        max = lena\n",
    "print(i, k, len(bb), len(bc), len(s), max, k*100/i)\n",
    "print(max, np.mean(mm), np.std(mm))\n",
    "\n",
    "# Подготовка\n",
    "characters = tuple(s)\n",
    "int2char = dict(enumerate(characters))\n",
    "char2int = {char: index for index, char in int2char.items()}\n",
    "vocab_size = len(char2int)\n",
    "print(vocab_size)\n",
    "\n",
    "train_size = int(len(bc) * 0.8)\n",
    "print(train_size)\n",
    "b_train = bc[:train_size]\n",
    "b_test = bc[train_size:]\n",
    "print(len(b_train), len(b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29636\n",
      "29636 7409\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, seq_len, vocab_size, embed_size, hidden_size, batch_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len        \n",
    "        self.vocab_size = vocab_size        \n",
    "        self.embed_size = embed_size        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size        \n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=self.embed_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        \n",
    "        #print('embedded=', embedded.size())\n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        \n",
    "        #  batch_size x seq_len x hidden_size\n",
    "        \n",
    "        output = self.fc(output)\n",
    "\n",
    "        #batch_size x seq_len x vocab_size\n",
    "        #output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):        \n",
    "        return torch.zeros(self.n_layers, self.batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blon                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.508923032164008"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    i = 0\n",
    "    for x_train, y_train in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "        \n",
    "        i += 1\n",
    "        #if i > 10: break\n",
    "            \n",
    "        output, hidden = model(x_train, hidden)\n",
    "        \n",
    "        out = output.contiguous().view(batch_size * seq_len, vocab_size)\n",
    "        y = y_train.contiguous().view(batch_size * seq_len)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        \n",
    "        logging.info(str(epoch) + ' ' + str(i) + ' ' + str(output.size()) + ' ' +str(loss.item()))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / i\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "\n",
    "        i = 0\n",
    "        for x_test, y_test in iterator:\n",
    "        \n",
    "            i += 1\n",
    "            hidden = model.init_hidden()\n",
    "            \n",
    "            output, hidden = model(x_test, hidden)\n",
    "            \n",
    "            out = output.contiguous().view(batch_size * seq_len, vocab_size)\n",
    "            y = y_test.contiguous().view(batch_size * seq_len)\n",
    "            \n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / i\n",
    "\n",
    "def perplexity(model, iterator):\n",
    "    \n",
    "    model.eval()    \n",
    "    hidden = torch.zeros(1, 1, hidden_size)    \n",
    "    pp = 0\n",
    "    N = batch_size * seq_len\n",
    "    #print(batch_size, seq_len, N)\n",
    "    \n",
    "    MIN = 1e-15\n",
    "    full = np.full((N, vocab_size), MIN)\n",
    "    softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    i = 0\n",
    "    for x_test, y_test in iterator:\n",
    "        \n",
    "        i += 1\n",
    "        #if i > 2: break\n",
    "        \n",
    "        hidden = model.init_hidden()\n",
    "            \n",
    "        output, hidden = model(x_test, hidden)\n",
    "            \n",
    "        output = softmax(output)\n",
    "            \n",
    "        #print(i, output.size())                        \n",
    "        x = output.detach().numpy()\n",
    "        #x = np.maximum(x, full)\n",
    "        ind = y_test.numpy()\n",
    "         \n",
    "        #print(x.shape, ind.shape)\n",
    "        ppb = 0\n",
    "            \n",
    "        for b in range(batch_size):\n",
    "            for s in range(seq_len):\n",
    "                k = ind[b,s]\n",
    "                prob = x[b,s,k]\n",
    "                ppb += prob * np.log(prob) \n",
    "            \n",
    "        ppb = ppb / batch_size\n",
    "        \n",
    "        #print(i, ppb)\n",
    "        pp += ppb\n",
    "\n",
    "    pp = np.exp(-1 * pp / i)\n",
    "    return pp\n",
    "\n",
    "def temp(d, t=0.5):\n",
    "    d = np.log(d) / t\n",
    "    d = np.exp(d)\n",
    "    return d / np.sum(d)\n",
    "    \n",
    "def generate(model, prime_str='Z', temp=0.1):\n",
    "    hidden = torch.zeros(1, 1, hidden_size)\n",
    "    pred = prime_str\n",
    "    for i in range(1, seq_len):\n",
    "        name = neq(pred, seq_len)  \n",
    "        x = np.array([char2int[char] for char in name])\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = torch.from_numpy(x).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        \n",
    "        preds = y[0, i - 1].detach().numpy()\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        preds = np.log(preds) / temp\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / (np.sum(exp_preds) * 1.0001)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        ind = np.argmax(probas)\n",
    "        \n",
    "        char = int2char[ind]\n",
    "        pred = pred + char\n",
    "\n",
    "    print(pred)\n",
    "    \n",
    "\n",
    "generate(model, 'B')    \n",
    "test_iterator = iter_names(b_test, batch_size, seq_len, vocab_size)\n",
    "perplexity(model, test_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7921,  1.1705, -2.1102],\n",
      "        [ 1.2458,  0.3617, -0.7323]])\n",
      "tensor([[0.1192, 0.8488, 0.0319],\n",
      "        [0.6446, 0.2663, 0.0892]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 30\n",
    "batch_size = 64\n",
    "embed_size = 16\n",
    "vocab_size = len(char2int)\n",
    "hidden_size = 16\n",
    "lr = 0.001\n",
    "\n",
    "model = CharRNN(seq_len=seq_len, vocab_size=vocab_size, \n",
    "                embed_size=embed_size, hidden_size=hidden_size, batch_size=batch_size)                \n",
    "                \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | elapsed=17.2 | Loss: 1.803 | Perplexity: 20.901 \n",
      "epoch=1 | elapsed=17.1 | Loss: 1.080 | Perplexity: 15.131 \n",
      "epoch=2 | elapsed=17.2 | Loss: 1.002 | Perplexity: 15.443 \n",
      "epoch=3 | elapsed=17.1 | Loss: 0.961 | Perplexity: 15.345 \n",
      "epoch=4 | elapsed=17.3 | Loss: 0.933 | Perplexity: 14.875 \n",
      "epoch=5 | elapsed=17.0 | Loss: 0.917 | Perplexity: 14.770 \n",
      "epoch=6 | elapsed=16.8 | Loss: 0.906 | Perplexity: 15.115 \n",
      "epoch=7 | elapsed=17.2 | Loss: 0.897 | Perplexity: 14.835 \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_epochs = 10\n",
    "print_every = 1\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    \n",
    "    old_loss = loss\n",
    "    \n",
    "    train_iterator = iter_names(b_train, batch_size, seq_len, vocab_size)\n",
    "    \n",
    "    loss = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    test_iterator = iter_names(b_test, batch_size, seq_len, vocab_size)\n",
    "    \n",
    "    pp = perplexity(model, test_iterator)\n",
    "    \n",
    "    logging.info(str(epoch) + ' ' +str(loss))\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        elapsed = time.time() - start\n",
    "        print(f'epoch={epoch} | elapsed={elapsed:.1f} | Loss: {loss:.3f} | Perplexity: {pp:.3f} ')  \n",
    "        start = time.time()\n",
    "        torch.save(model, \"rnn1.pt\")\n",
    "        \n",
    "    if np.abs(loss - old_loss) < 0.01:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bath_size = 4\n",
    "epoch=0 | elapsed=32.2 | Loss: 1.198 | Perplexity: 14.596 \n",
    "epoch=1 | elapsed=32.4 | Loss: 0.942 | Perplexity: 14.586 \n",
    "epoch=2 | elapsed=32.7 | Loss: 0.901 | Perplexity: 15.696 \n",
    "epoch=3 | elapsed=32.5 | Loss: 0.883 | Perplexity: 15.113 \n",
    "epoch=4 | elapsed=32.2 | Loss: 0.872 | Perplexity: 14.723 \n",
    "epoch=5 | elapsed=32.2 | Loss: 0.863 | Perplexity: 15.122 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_epochs(n_epochs = 100, print_every = 1, \n",
    "        batch_size=128, hidden_size=16, embed_size = 16):\n",
    "    \n",
    "    seq_len = 30\n",
    "    embed_size = embed_size\n",
    "    vocab_size = len(char2int)\n",
    "    hidden_size = hidden_size\n",
    "    lr = 0.001\n",
    "\n",
    "    model = CharRNN(seq_len=seq_len, vocab_size=vocab_size, \n",
    "                embed_size=embed_size, hidden_size=hidden_size, batch_size=batch_size)                \n",
    "                \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    n_epochs = 20\n",
    "    print_every = 1\n",
    "    loss = 0\n",
    "\n",
    "    for epoch in range(n_epochs + 1):\n",
    "    \n",
    "        old_loss = loss\n",
    "        train_iterator = iter_names(b_train, batch_size, seq_len, vocab_size)\n",
    "        loss = train(model, train_iterator, optimizer, criterion)\n",
    "        #test_iterator = iter_names(b_test, batch_size, seq_len, vocab_size)\n",
    "        #loss2 = evaluate(model, test_iterator, criterion)\n",
    "        logging.info(str(epoch) + ' ' +str(loss))\n",
    "        if epoch % print_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(f'epoch={epoch} | elapsed={elapsed:.1f} | Loss: {loss:.3f}')  \n",
    "            start = time.time()\n",
    "            #torch.save(model, \"rnn1.pt\")\n",
    "        \n",
    "        if np.abs(loss - old_loss) < 0.01:\n",
    "            break\n",
    "    return loss, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 8\n",
      "epoch=0 | elapsed=50.6 | Loss: 1.084\n",
      "epoch=1 | elapsed=50.0 | Loss: 0.903\n",
      "epoch=2 | elapsed=50.7 | Loss: 0.876\n",
      "epoch=3 | elapsed=49.1 | Loss: 0.861\n",
      "epoch=4 | elapsed=50.0 | Loss: 0.852\n",
      "batch_size= 16\n",
      "epoch=0 | elapsed=29.8 | Loss: 1.255\n",
      "epoch=1 | elapsed=29.2 | Loss: 0.960\n",
      "epoch=2 | elapsed=29.7 | Loss: 0.916\n",
      "epoch=3 | elapsed=30.5 | Loss: 0.893\n",
      "epoch=4 | elapsed=29.8 | Loss: 0.880\n",
      "epoch=5 | elapsed=30.1 | Loss: 0.870\n",
      "batch_size= 32\n",
      "epoch=0 | elapsed=19.7 | Loss: 1.436\n",
      "epoch=1 | elapsed=19.6 | Loss: 0.990\n",
      "epoch=2 | elapsed=20.0 | Loss: 0.936\n",
      "epoch=3 | elapsed=20.3 | Loss: 0.910\n",
      "epoch=4 | elapsed=20.2 | Loss: 0.894\n",
      "epoch=5 | elapsed=19.8 | Loss: 0.882\n",
      "epoch=6 | elapsed=20.6 | Loss: 0.872\n",
      "batch_size= 64\n",
      "epoch=0 | elapsed=15.3 | Loss: 1.743\n",
      "epoch=1 | elapsed=15.0 | Loss: 1.098\n",
      "epoch=2 | elapsed=15.2 | Loss: 1.013\n",
      "epoch=3 | elapsed=15.2 | Loss: 0.966\n",
      "epoch=4 | elapsed=15.4 | Loss: 0.936\n",
      "epoch=5 | elapsed=15.3 | Loss: 0.917\n",
      "epoch=6 | elapsed=15.1 | Loss: 0.903\n",
      "epoch=7 | elapsed=15.3 | Loss: 0.892\n",
      "epoch=8 | elapsed=14.7 | Loss: 0.883\n",
      "batch_size= 128\n",
      "epoch=0 | elapsed=12.9 | Loss: 2.324\n",
      "epoch=1 | elapsed=12.9 | Loss: 1.242\n",
      "epoch=2 | elapsed=13.2 | Loss: 1.122\n",
      "epoch=3 | elapsed=13.1 | Loss: 1.057\n",
      "epoch=4 | elapsed=12.7 | Loss: 1.017\n",
      "epoch=5 | elapsed=12.9 | Loss: 0.986\n",
      "epoch=6 | elapsed=13.2 | Loss: 0.965\n",
      "epoch=7 | elapsed=13.2 | Loss: 0.950\n",
      "epoch=8 | elapsed=12.9 | Loss: 0.938\n",
      "epoch=9 | elapsed=12.8 | Loss: 0.927\n",
      "epoch=10 | elapsed=13.2 | Loss: 0.918\n",
      "batch_size= 256\n",
      "epoch=0 | elapsed=11.7 | Loss: 2.992\n",
      "epoch=1 | elapsed=11.6 | Loss: 1.567\n",
      "epoch=2 | elapsed=11.3 | Loss: 1.324\n",
      "epoch=3 | elapsed=11.5 | Loss: 1.209\n",
      "epoch=4 | elapsed=11.7 | Loss: 1.143\n",
      "epoch=5 | elapsed=11.6 | Loss: 1.099\n",
      "epoch=6 | elapsed=11.5 | Loss: 1.069\n",
      "epoch=7 | elapsed=11.4 | Loss: 1.046\n",
      "epoch=8 | elapsed=11.6 | Loss: 1.027\n",
      "epoch=9 | elapsed=11.7 | Loss: 1.013\n",
      "epoch=10 | elapsed=11.8 | Loss: 0.999\n",
      "epoch=11 | elapsed=11.6 | Loss: 0.985\n",
      "epoch=12 | elapsed=11.4 | Loss: 0.972\n",
      "epoch=13 | elapsed=11.7 | Loss: 0.960\n",
      "epoch=14 | elapsed=11.8 | Loss: 0.950\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [8,16,32,64,128,256]:\n",
    "    print('batch_size=', batch_size)\n",
    "    loss, epoch = start_epochs(batch_size=batch_size)\n",
    "    print('batch_size=', batch_size, 'loss=', loss, 'epoch=', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size= 8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[240, 80]' is invalid for input of size 307200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-04379dbb1530>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidden_size='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidden_size='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-cdf58d7f4fca>\u001b[0m in \u001b[0;36mstart_epochs\u001b[1;34m(n_epochs, print_every, batch_size, hidden_size, embed_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mold_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtrain_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#test_iterator = iter_names(b_test, batch_size, seq_len, vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#loss2 = evaluate(model, test_iterator, criterion)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-7e04f7092c87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#print('=2', output.size(), y_train.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[240, 80]' is invalid for input of size 307200"
     ]
    }
   ],
   "source": [
    "for hidden_size in [8,16,32,64,128,256]:\n",
    "    print('hidden_size=', hidden_size)\n",
    "    loss, epoch = start_epochs(hidden_size=hidden_size)\n",
    "    print('hidden_size=', hidden_size, 'loss=', loss, 'epoch=', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_size= 8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[240, 80]' is invalid for input of size 307200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-1f7b324265b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0membed_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'embed_size='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'embed_size='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-cdf58d7f4fca>\u001b[0m in \u001b[0;36mstart_epochs\u001b[1;34m(n_epochs, print_every, batch_size, hidden_size, embed_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mold_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtrain_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#test_iterator = iter_names(b_test, batch_size, seq_len, vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#loss2 = evaluate(model, test_iterator, criterion)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-7e04f7092c87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#print('=2', output.size(), y_train.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[240, 80]' is invalid for input of size 307200"
     ]
    }
   ],
   "source": [
    "for embed_size in [8,16,32,64,128,256]:\n",
    "    print('embed_size=', embed_size)\n",
    "    loss, epoch = start_epochs(embed_size=embed_size)\n",
    "    print('embed_size=', embed_size, 'loss=', loss, 'epoch=', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ble                           \n",
      "Cor                           \n",
      "Dest                          \n",
      "En                            \n",
      "Fate                          \n",
      "Int                           \n",
      "Kation                        \n",
      "Le                            \n",
      "Ne                            \n",
      "Or                            \n",
      "Sate                          \n",
      "Yer                           \n",
      "Zate                          \n"
     ]
    }
   ],
   "source": [
    "# 32 \n",
    "generate(model, 'B')  \n",
    "generate(model, 'C')  \n",
    "generate(model, 'D')  \n",
    "generate(model, 'E')  \n",
    "generate(model, 'F')  \n",
    "generate(model, 'I')  \n",
    "generate(model, 'K')  \n",
    "generate(model, 'L')  \n",
    "generate(model, 'N')  \n",
    "generate(model, 'O')  \n",
    "generate(model, 'S')  \n",
    "generate(model, 'Y')\n",
    "generate(model, 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bere                          \n",
      "Creent                        \n",
      "Deet                          \n",
      "Ere                           \n",
      "Fere                          \n",
      "Inferte                       \n",
      "Kreen                         \n",
      "Lest                          \n",
      "Nere                          \n",
      "Ore                           \n",
      "Sere                          \n",
      "Yer                           \n",
      "Zer                           \n"
     ]
    }
   ],
   "source": [
    "# 64\n",
    "generate(model, 'B')  \n",
    "generate(model, 'C')  \n",
    "generate(model, 'D')  \n",
    "generate(model, 'E')  \n",
    "generate(model, 'F')  \n",
    "generate(model, 'I')  \n",
    "generate(model, 'K')  \n",
    "generate(model, 'L')  \n",
    "generate(model, 'N')  \n",
    "generate(model, 'O')  \n",
    "generate(model, 'S')  \n",
    "generate(model, 'Y')\n",
    "generate(model, 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ble                           \n",
      "Corte                         \n",
      "Death                         \n",
      "Exer                          \n",
      "Fate                          \n",
      "In                            \n",
      "Kan                           \n",
      "Len                           \n",
      "Nest                          \n",
      "Or                            \n",
      "Son                           \n",
      "Yor                           \n",
      "Zon                           \n"
     ]
    }
   ],
   "source": [
    "# 16\n",
    "generate(model, 'B')  \n",
    "generate(model, 'C')  \n",
    "generate(model, 'D')  \n",
    "generate(model, 'E')  \n",
    "generate(model, 'F')  \n",
    "generate(model, 'I')  \n",
    "generate(model, 'K')  \n",
    "generate(model, 'L')  \n",
    "generate(model, 'N')  \n",
    "generate(model, 'O')  \n",
    "generate(model, 'S')  \n",
    "generate(model, 'Y')\n",
    "generate(model, 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bear                          \n",
      "Core                          \n",
      "Dead                          \n",
      "Ener                          \n",
      "Face                          \n",
      "Inferna                       \n",
      "Karna                         \n",
      "Lest                          \n",
      "Near                          \n",
      "Ober                          \n",
      "Sarna                         \n",
      "Yorie                         \n",
      "Zorn                          \n"
     ]
    }
   ],
   "source": [
    "# 256\n",
    "generate(model, 'B')  \n",
    "generate(model, 'C')  \n",
    "generate(model, 'D')  \n",
    "generate(model, 'E')  \n",
    "generate(model, 'F')  \n",
    "generate(model, 'I')  \n",
    "generate(model, 'K')  \n",
    "generate(model, 'L')  \n",
    "generate(model, 'N')  \n",
    "generate(model, 'O')  \n",
    "generate(model, 'S')  \n",
    "generate(model, 'Y')\n",
    "generate(model, 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"rnn1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.762455737114973"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.287)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU\n",
      "64\n",
      "16\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.rnn.mode)\n",
    "print(model.rnn.hidden_size)\n",
    "print(model.rnn.input_size)\n",
    "print(model.rnn.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neq= 12345 =\n",
      "next_= 23456<EOS> =\n",
      "next_= 23456  =\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6c65920c0ea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'next_='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_char\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'123456'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Формирование итератора батчей\n",
    "\n",
    "# Выравнивает строки\n",
    "def neq(name, seq_len):\n",
    "    n_len = len(name)\n",
    "    if n_len > seq_len:\n",
    "        name = name[0:seq_len]\n",
    "    elif n_len < seq_len:\n",
    "        name += ' ' * (seq_len - n_len)\n",
    "    return name     \n",
    "\n",
    "# Выделяет +1 символ\n",
    "def y_char(name, end='<EOS>'):\n",
    "    out = ''\n",
    "    for i, char in enumerate(name):\n",
    "        a = end\n",
    "        if i < len(name) - 1:\n",
    "            a = name[i+1]\n",
    "        out = out + str(a)\n",
    "    return out\n",
    "\n",
    "def iter_names(arr, batch_size, seq_len, vocab_size):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size х seq_len x vocab_size from _shuffled_ list arr.\n",
    "    '''\n",
    "# Перемешивание списка перед отбрасыванием последнего батча    \n",
    "    arr = shuffle(arr)\n",
    "    num_batches = len(arr) // batch_size\n",
    "    i = -1\n",
    "    for _ in range(num_batches):\n",
    "        for n in range(batch_size):\n",
    "            i += 1\n",
    "# Выравнивание        \n",
    "            name = neq(arr[i], seq_len)\n",
    "# Кодирование\n",
    "            encoded = np.array([char2int[char] for char in name])\n",
    "            encoded = np.expand_dims(encoded, axis=0)            \n",
    "            y_enc = np.array([char2int[char] for char in y_char(name, ' ')])\n",
    "            y_enc = np.expand_dims(y_enc, axis=0)            \n",
    "        \n",
    "            if n == 0:\n",
    "                batch = encoded\n",
    "                y = y_enc\n",
    "            else:\n",
    "                batch = np.vstack([batch, encoded])\n",
    "                y = np.vstack([y, y_enc])                \n",
    "\n",
    "        x_train = torch.from_numpy(batch).type(torch.LongTensor)\n",
    "        y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        \n",
    "        yield x_train, y_train\n",
    "    \n",
    "# Тестирование\n",
    "\n",
    "print('neq=', neq('123456', 5), '=')\n",
    "print('next_=', y_char('123456'), '=')\n",
    "print('next_=', y_char('123456', ' '), '=')\n",
    "\n",
    "iterator = iter_names(bc, batch_size, seq_len, vocab_size)\n",
    "\n",
    "for i, batch in enumerate(iterator):\n",
    "    print(i)\n",
    "    print(batch)\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1 2\n",
      "1 2 2 3\n",
      "2 3 3 4\n",
      "3 4 4 5\n",
      "4 5 5 6\n",
      "5 6 6 <EOS>\n"
     ]
    }
   ],
   "source": [
    "name = '123456'\n",
    "for i, char in enumerate(name):\n",
    "    a = '<EOS>'\n",
    "    if i < len(name) - 1:\n",
    "        a = name[i+1]\n",
    "    print(i, char, name[i], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for n in range(0, arr.shape[1], n_characters):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_characters]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_characters]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 1)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6337, -0.1962, -0.9395,  2.0448,  0.6950, -1.4131,  0.7850,\n",
       "          -0.6797,  0.4859,  1.9454],\n",
       "         [-1.3249,  0.4864,  2.5068, -1.1342,  1.0313,  0.4100,  0.4534,\n",
       "           0.8884,  1.4118, -0.1342],\n",
       "         [ 0.7127, -0.8053,  0.3178, -1.2541,  0.2893, -0.6870,  0.3931,\n",
       "           0.0118, -0.2734,  0.3824]],\n",
       "\n",
       "        [[-0.5266, -0.4211, -0.6652, -0.8173,  0.9448,  0.5364, -0.5564,\n",
       "           2.2261, -0.7277, -1.4443],\n",
       "         [-0.0916,  0.6066, -0.5304, -0.9550, -1.5262, -1.1030,  1.4552,\n",
       "          -0.2243,  0.2030, -0.2679],\n",
       "         [-1.4104, -0.1019,  0.4064, -0.4814, -1.6543,  0.8848, -0.5563,\n",
       "           0.5205, -0.1476, -2.2875]],\n",
       "\n",
       "        [[-0.4309,  0.5035, -1.3085,  0.2668, -1.0268, -2.1498,  0.2492,\n",
       "          -1.4792,  1.1589,  0.5369],\n",
       "         [-0.4977,  0.3572,  1.5036, -0.9054, -0.5078,  0.5203,  0.0280,\n",
       "          -0.8152, -0.1462,  0.7483],\n",
       "         [ 0.1124, -0.5138,  0.3559,  0.7478, -1.5586,  0.4941,  1.0005,\n",
       "           1.8800,  0.5192, -0.7816]],\n",
       "\n",
       "        [[ 0.1090, -0.1580, -0.1685,  1.3101, -0.0606, -1.0876, -0.7255,\n",
       "          -0.1648,  1.2221, -2.4030],\n",
       "         [-1.4193, -0.0904, -0.2207,  1.1462,  0.6782,  0.1796, -0.3047,\n",
       "          -0.1434,  0.3155,  1.3324],\n",
       "         [ 0.9632, -0.5292, -1.7592, -2.2456, -0.4996, -0.7256, -0.7026,\n",
       "           0.8201,  0.1509, -0.4524]],\n",
       "\n",
       "        [[ 0.3022, -1.2791, -0.2197, -0.3353,  0.0731,  0.3459,  0.2611,\n",
       "          -1.3961,  1.1503,  0.4328],\n",
       "         [ 0.7989, -0.0564, -0.5329, -1.0708,  0.8061, -0.9583, -0.5691,\n",
       "          -1.8539, -0.0730,  0.6932],\n",
       "         [-0.7281,  0.1554,  0.8084,  0.6797,  0.3351, -0.0551, -1.4961,\n",
       "           1.3245,  1.0775,  0.3040]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 11.69481777110779\n",
      "11 14.114137832173334\n",
      "12 16.70247888380647\n",
      "13 19.441027523242983\n",
      "14 22.310251200497344\n",
      "15 25.29013197636867\n",
      "16 28.360400525285023\n",
      "17 31.500766529656087\n",
      "18 34.69114178717895\n",
      "19 37.91185260315368\n",
      "20 41.14383835805802\n",
      "21 44.36883351652059\n",
      "22 47.56953076625502\n",
      "23 50.72972343239856\n",
      "24 53.83442579145289\n",
      "25 56.8699703969464\n",
      "26 59.8240820135939\n",
      "27 62.68592822632421\n",
      "28 65.44614723423994\n",
      "29 68.0968537477777\n",
      "30 70.63162427192687\n",
      "31 73.04546337286439\n",
      "32 75.33475278503207\n",
      "33 77.4971854175772\n",
      "34 79.53168646201543\n",
      "35 81.43832388747153\n",
      "36 83.21821063798795\n",
      "37 84.87340082163846\n",
      "38 86.40678210821208\n",
      "39 87.8219664366722\n",
      "40 89.1231809817949\n",
      "41 90.31516114817354\n",
      "42 91.40304715618693\n",
      "43 92.39228556561199\n",
      "44 93.28853685514264\n",
      "45 94.09758994657749\n",
      "46 94.82528433672547\n",
      "47 95.47744028332993\n",
      "48 96.05979728794225\n",
      "49 96.57796093226764\n",
      "50 97.03735795779885\n",
      "51 97.44319933344283\n",
      "52 97.80045093342753\n",
      "53 98.11381134839128\n",
      "54 98.38769627588515\n",
      "55 98.62622888164461\n",
      "56 98.83323548852007\n",
      "57 99.01224593411699\n",
      "58 99.16649793892613\n",
      "59 99.2989448417817\n"
     ]
    }
   ],
   "source": [
    "for n in range(10,60):\n",
    "    q = 1.0\n",
    "    for k in range(n):\n",
    "        q = q * (365 - k) / 365\n",
    "    p = (1 -q) * 100\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
