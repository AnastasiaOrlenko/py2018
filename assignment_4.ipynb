{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание работы после ячейки 72.\n",
    "\n",
    "# Assignment 4: Named entity recognition\n",
    "\n",
    "Построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Используйте в своем решении ансамбли над решающими деревьями: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost) \n",
    "Tutorials:  \n",
    "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
    "1. https://github.com/catboost/tutorials \n",
    "\n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей   \n",
    "\n",
    "bonus, think about:  \n",
    "1. How can you exploit that words belong to some sentence?\n",
    "2. Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word tag  \n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   O  \n",
       "1    __START1__     __START1__      Thousands           1.0             of   O  \n",
       "2           NNS      Thousands             of           1.0  demonstrators   O  \n",
       "3            IN             of  demonstrators           1.0           have   O  \n",
       "4           NNS  demonstrators           have           1.0        marched   O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_short.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        57032\n",
       "B-geo     1846\n",
       "B-gpe     1400\n",
       "B-org     1354\n",
       "I-per     1190\n",
       "B-tim     1132\n",
       "B-per     1024\n",
       "I-org      932\n",
       "I-geo      360\n",
       "I-tim      284\n",
       "B-art       92\n",
       "I-gpe       56\n",
       "I-art       50\n",
       "B-eve       42\n",
       "I-eve       34\n",
       "B-nat       30\n",
       "I-nat       16\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx next-next-pos next-next-word next-pos      next-word  pos  \\\n",
       "0           1.0           NNS  demonstrators       IN             of  NNS   \n",
       "1           1.0           VBP           have      NNS  demonstrators   IN   \n",
       "2           1.0           VBN        marched      VBP           have  NNS   \n",
       "3           1.0            IN        through      VBN        marched  VBP   \n",
       "4           1.0           NNP         London       IN        through  VBN   \n",
       "\n",
       "     prev-pos prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0  __START1__    __START2__     __START2__     __START1__      Thousands   O   \n",
       "1         NNS    __START1__     __START1__      Thousands             of   O   \n",
       "2          IN           NNS      Thousands             of  demonstrators   O   \n",
       "3         NNS            IN             of  demonstrators           have   O   \n",
       "4         VBP           NNS  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN          8702\n",
      "IN          7548\n",
      "NNP         6848\n",
      "DT          5346\n",
      "NNS         4488\n",
      "JJ          4348\n",
      "__END1__    3000\n",
      "__END2__    3000\n",
      ".           2998\n",
      "VBD         2194\n",
      "VBN         2074\n",
      ",           1836\n",
      "VB          1598\n",
      "VBZ         1454\n",
      "TO          1446\n",
      "CD          1430\n",
      "CC          1396\n",
      "VBG         1194\n",
      "RB          1118\n",
      "VBP          944\n",
      "PRP          680\n",
      "POS          542\n",
      "PRP$         522\n",
      "MD           460\n",
      "``           244\n",
      "JJR          192\n",
      "WDT          190\n",
      "JJS          172\n",
      "WRB          160\n",
      "WP           144\n",
      "RP           140\n",
      "NNPS         124\n",
      "$             68\n",
      ":             56\n",
      "RBR           52\n",
      "RRB           40\n",
      "LRB           40\n",
      "EX            34\n",
      ";             20\n",
      "RBS           14\n",
      "PDT           12\n",
      "WP$            6\n",
      "Name: next-next-pos, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['$', ',', '.', ':', ';', 'CC', 'CD', 'DT', 'EX', 'IN', 'JJ', 'JJR',\n",
       "       'JJS', 'LRB', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS',\n",
       "       'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'RRB', 'TO', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB',\n",
       "       '__START1__', '__START2__', '``'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.pos)\n",
    "print(tdf['next-next-pos'].value_counts())\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``' '__START2__' '__START1__' 'WRB' 'WP$']\n",
      "[40]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: ['__END1__']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2170b3528a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m39\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m38\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m37\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__START2__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__END1__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[1;32m---> 53\u001b[1;33m                              % str(diff))\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: ['__END1__']"
     ]
    }
   ],
   "source": [
    "le.classes_\n",
    "print(le.inverse_transform([41, 40, 39, 38, 37]))\n",
    "print(le.transform(['__START2__']))\n",
    "print(le.transform(['__END1__']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            O\n",
       "1            O\n",
       "2            O\n",
       "3            O\n",
       "4            O\n",
       "5            O\n",
       "6        B-geo\n",
       "7            O\n",
       "8            O\n",
       "9            O\n",
       "10           O\n",
       "11           O\n",
       "12       B-geo\n",
       "13           O\n",
       "14           O\n",
       "15           O\n",
       "16           O\n",
       "17           O\n",
       "18       B-gpe\n",
       "19           O\n",
       "20           O\n",
       "21           O\n",
       "22           O\n",
       "23           O\n",
       "24           O\n",
       "25           O\n",
       "26           O\n",
       "27           O\n",
       "28           O\n",
       "29           O\n",
       "         ...  \n",
       "66844        O\n",
       "66845        O\n",
       "66846        O\n",
       "66847        O\n",
       "66848        O\n",
       "66849        O\n",
       "66850        O\n",
       "66851        O\n",
       "66852        O\n",
       "66853        O\n",
       "66854        O\n",
       "66855        O\n",
       "66856        O\n",
       "66857        O\n",
       "66858        O\n",
       "66859        O\n",
       "66860    B-per\n",
       "66861        O\n",
       "66862        O\n",
       "66863        O\n",
       "66864        O\n",
       "66865        O\n",
       "66866        O\n",
       "66867        O\n",
       "66868        O\n",
       "66869        O\n",
       "66870        O\n",
       "66871        O\n",
       "66872        O\n",
       "66873        O\n",
       "Name: tag, Length: 66874, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df\n",
    "le.classes_\n",
    "df.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
    "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# some wrappers to work with word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "   \n",
    "class Word2VecWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
    "        self.window_ = window\n",
    "        self.negative_ = negative\n",
    "        self.size_ = size\n",
    "        self.iter_ = iter\n",
    "        self.is_cbow_ = is_cbow\n",
    "        self.w2v = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        self.w2v = Word2Vec(sentences_list, \n",
    "                            window=self.window_,\n",
    "                            negative=self.negative_, \n",
    "                            size=self.size_, \n",
    "                            iter=self.iter_,\n",
    "                            sg=not self.is_cbow_, seed=self.random_state)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.w2v\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: a list of words\n",
    "        \"\"\"\n",
    "        if self.w2v is None:\n",
    "            raise Exception('model not fitted')\n",
    "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we exploit that word2vec is an unsupervised learning algorithm\n",
    "# so we can train it on the whole dataset (subject to discussion)\n",
    "\n",
    "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
    "\n",
    "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
    "w2v_cbow.fit(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.05887736725599869\n",
      "test 0.060439542712750365\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 1 \n",
    "# random labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', DummyClassifier(random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36858</th>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39120</th>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53612</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28439</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43719</th>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59363</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56283</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24875</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17269</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21061</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37458</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9705</th>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62386</th>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25568</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45126</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34343</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62984</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39893</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34898</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57851</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54521</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61975</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37268</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24162</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18117</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37976</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52178</th>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16531</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46469</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40840</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25888</th>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17812</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35704</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23270</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27663</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38110</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51080</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66777</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18444</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65218</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63706</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17158</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39474</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45771</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57152</th>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22790</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pos  next-pos  next-next-pos  prev-pos  prev-prev-pos\n",
       "36858   30        18             35        16             16\n",
       "39120   32        28              7        30              5\n",
       "53612    7        10             15        30              1\n",
       "6150     7        15              9         9              1\n",
       "3771    16         1             10        15             16\n",
       "28439    7        15              1         9             15\n",
       "43719   28        23             29        18             15\n",
       "59363    9        10             16        18             30\n",
       "14674    9        16              1        15             10\n",
       "56283    1         5             30        18              9\n",
       "14818   16         9             31        16              7\n",
       "16970   34         7             10        16             16\n",
       "24875    7        15             15        39             40\n",
       "17269    3         5             23        32             23\n",
       "21061   15         2             39        10              5\n",
       "37458   23         6             18        34             21\n",
       "9705     5        34             32        10             18\n",
       "62386   34         9             15        15              7\n",
       "25568   16        18              9        36              1\n",
       "45126   16        15             35        20             15\n",
       "34343   10        16             18         9             23\n",
       "62984    9         6              2        18              6\n",
       "7534     9        16             16        15             15\n",
       "39893    1         5             34        18             32\n",
       "47995   18        30             16        15             16\n",
       "34898   18         7             15        31             33\n",
       "521     33        32              2        18              5\n",
       "57851    9         7             18        32             15\n",
       "54521   18         9              7        32             34\n",
       "61975   31         7              6        15              7\n",
       "...    ...       ...            ...       ...            ...\n",
       "37268    7        15             28        29             14\n",
       "24162   10        18             33        39             40\n",
       "18117    7         9             15         9             12\n",
       "37976   32         9             15        23             33\n",
       "21597   16        16             34        16             39\n",
       "52178   18        33             32        39             40\n",
       "387     11        15             18         5             18\n",
       "16531    6         9              6         0             29\n",
       "46469   10        15              2         7              9\n",
       "40840   33        32             16        18             15\n",
       "664      9         7             15        18              6\n",
       "25888   21        30              9         5             39\n",
       "17812   16        15             23        20             16\n",
       "35704   33        32              9        21              9\n",
       "23270    5        10             15        16             16\n",
       "27663   28        29             16        16              7\n",
       "38110   16         2             39        10              5\n",
       "51080    9        15             15        18              9\n",
       "66777   15         9              7         7              9\n",
       "18444   15         9              7         7              9\n",
       "65218   16        17              2         7              5\n",
       "63706   10        18             31         9             15\n",
       "6800     1         6              1         6              7\n",
       "2129    30        32              9        15              7\n",
       "39153   30         9              7        16             15\n",
       "17158    9         7             16        15              7\n",
       "39474   24         7             15        16             28\n",
       "45771    1         5             15        18              1\n",
       "57152   16        34              7        16             16\n",
       "22790    9        22             15        32             33\n",
       "\n",
       "[50155 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.46639500282346874\n",
      "test 0.39660981421559566\n",
      "Wall time: 18min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 2 \n",
    "# pos features + one hot encoding + logistic regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
    "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) #######################################\n",
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "X_train = enc.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "X_test = enc.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50155, 206) (16719, 206)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "#print(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.747052570135\n",
      "test 0.599419020457\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_ = clf.predict(X_train)\n",
    "#print('test', metrics.f1_score(y_train, y_pred_, average='macro'))\n",
    "#print('test', metrics.f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne= 10 f1= 0.577316050586\n",
      "ne= 20 f1= 0.59896942209\n",
      "ne= 50 f1= 0.598170527645\n",
      "ne= 100 f1= 0.599419020457\n",
      "ne= 200 f1= 0.597565971407\n",
      "ne= 500 f1= 0.60004113975\n"
     ]
    }
   ],
   "source": [
    "NE = [10, 20, 50, 100, 200, 500]\n",
    "for ne in NE:\n",
    "  clf = RandomForestClassifier(n_estimators=ne, n_jobs=-1, random_state=SEED)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  f1  = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "  print(\"ne=\", ne, \"f1=\", f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) ####################################\n",
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "NE = [10, 50, 100, 200, 500, 1000]\n",
    "for ne in NE:\n",
    "  clf = GradientBoostingClassifier(n_estimators=ne, learning_rate=0.1, random_state=SEED)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  f1  = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "  print(\"ne=\", ne, \"f1=\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание работы и выводы\n",
    "\n",
    "Основная работа выполнена в ячейках 64-79. Простое применение RF со стандартными параметрами привело к искомому результату: критерий f1-macro на тестовой выборке составил примерно 0.6, что значительно выше второго baseline 0.396.\n",
    "\n",
    "В примечаниях к заданию неоднократно указывалось, что нельзя подбирать гиперпараметры на тестовой выборке, но этого подбора путем кросс-валидации фактически не делалось, поскольу цель задания - превзойти второй baseline достигалась при фактически любом значение гиперпараметра, в т.ч. при значении по умолчанию - 100.\n",
    "\n",
    "Для сравнения использовался метод градиентного бустинга, который здесь дал значительно худше результаты 0.5-0.55. Гиперпараметр тоже не подбирался, но была сделана его примерная оценка.\n",
    "\n",
    "Критерий F1-macro выбран для того чтобы оценить среднее качество решения задачи NER путем классификации, он является здесь оптимальным, хотя ряд редких сущностей не может быть правильно определен из-за недостатка данных. Подойдет любая метрика, которая дает баланс точности и полноты для несбалансированных классов для многоклассовой классификации, но F1-macro является оптимальной, если нет необходимости как-то взвешивать разные типы NE.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Выводы\n",
    "\n",
    "Без учета слов, на данных грамматической разметки, RF для NER работает значительно лучше логистической регрессии, как и следовало ожидать ввиду специфики задачи, а вот обычный градиентный бустинг, без оптимизации в специализированных пакетах, дает гораздо худшие результаты.  \n",
    "\n",
    "Стандартный метод RF сразу дает хорошие результаты и решает задачу превышения baseline-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 3\n",
    "# use word2vec cbow embedding + baseline 2 + svm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import scipy.sparse as sp\n",
    "\n",
    "embeding = w2v_cbow\n",
    "encoder_pos = OneHotEncoder()\n",
    "X_train = sp.hstack([\n",
    "    embeding.transform(df_train.word),\n",
    "    embeding.transform(df_train['next-word']),\n",
    "    embeding.transform(df_train['next-next-word']),\n",
    "    embeding.transform(df_train['prev-word']),\n",
    "    embeding.transform(df_train['prev-prev-word']),\n",
    "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "X_test = sp.hstack([\n",
    "    embeding.transform(df_test.word),\n",
    "    embeding.transform(df_test['next-word']),\n",
    "    embeding.transform(df_test['next-next-word']),\n",
    "    embeding.transform(df_test['prev-word']),\n",
    "    embeding.transform(df_test['prev-prev-word']),\n",
    "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
    "                                    {'C': np.logspace(-4, 0, 5)}, \n",
    "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50155x1706 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 57925775 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16719, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = embeding.transform(df_test['next-word'])\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С= 0.1 f1= 0.803763528653904\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C=0.1\n",
    "clf = LinearSVC(C=C, random_state=SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1  = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "print(\"С=\", C, \"f1=\", f1)\n",
    "\n",
    "f11 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "print(f11)\n",
    "print(np.mean(f11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1= 0.8050354838121895\n",
      "Wall time: 13min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C=1\n",
    "clf = LogisticRegression(C=C, random_state=SEED)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1  = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "print(\"C=\", C, \"f1=\", f1)\n",
    "\n",
    "f11 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "print(f11)\n",
    "print(np.mean(f11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.66666667 0.89589905 0.81710914 0.6        0.81481481\n",
      " 0.8996139  0.92870201 0.6        0.85714286 0.86046512 0.75862069\n",
      " 0.66666667 0.86292135 0.91927512 0.79389313 0.9938127 ]\n",
      "0.8050354838121895\n"
     ]
    }
   ],
   "source": [
    "f11 = metrics.f1_score(y_test, y_pred, average=None)\n",
    "print(f11)\n",
    "print(np.mean(f11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  3, 16, ..., 16, 16, 16], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('enc', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)), ('est', LogisticRegressionCV(Cs=5, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
       "           random_state=1337, refit=True, scoring='f1_macro',\n",
       "           solver='newton-cg', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-114b1d3159a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66874,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "[   92    42  1846  1400    30  1354  1024  1132    50    34   360    56\n",
      "    16   932  1190   284 57032]\n"
     ]
    }
   ],
   "source": [
    "### Класс и их количество\n",
    "\n",
    "print(y.shape)\n",
    "uniqs, counts = np.unique(y, return_counts=True)\n",
    "print(uniqs)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66874,)\n",
      "2 [0 1] [65028  1846]\n"
     ]
    }
   ],
   "source": [
    "#### Конвертация многоклассовой задачи в бинарную\n",
    "\n",
    "def mc2(y, n):\n",
    "    y1 = y.copy()\n",
    "    y1[y==n] = 1\n",
    "    y1[y!=n] = 0\n",
    "    return y1\n",
    "\n",
    "y1 = mc2(y, 2)\n",
    "print(y1.shape)\n",
    "uniqs, counts = np.unique(y1, return_counts=True)\n",
    "print(2, uniqs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С= 0.1 f1= 0.860566448802\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "y1_train = mc2(y_train, 2)\n",
    "y1_test = mc2(y_test, 2)\n",
    "\n",
    "C=0.1\n",
    "clf = LinearSVC(C=C, random_state=SEED)\n",
    "clf.fit(X_train, y1_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1  = metrics.f1_score(y1_test, y_pred)\n",
    "print(\"f1=\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66874,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "[   92    42  1846  1400    30  1354  1024  1132    50    34   360    56\n",
      "    16   932  1190   284 57032]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 92 0.8636363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 42 0.5263157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1846 0.8674698795180722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1400 0.8059701492537314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 30 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1354 0.767741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1024 0.8825757575757577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1132 0.9314586994727592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 50 0.608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 34 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 360 0.7909604519774011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 56 0.6206896551724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 16 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 932 0.7948164146868251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 1190 0.8950819672131146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 284 0.8513513513513514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 57032 0.9919681519765331\n",
      "[0.8636363636363636, 0.5263157894736842, 0.8674698795180722, 0.8059701492537314, 0.6, 0.767741935483871, 0.8825757575757577, 0.9314586994727592, 0.608695652173913, 0.75, 0.7909604519774011, 0.6206896551724138, 0.6666666666666666, 0.7948164146868251, 0.8950819672131146, 0.8513513513513514, 0.9919681519765331]\n",
      "f1-macro: 0.7773764050372033\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "######\n",
    "\n",
    "print(y.shape)\n",
    "uniqs, counts = np.unique(y, return_counts=True)\n",
    "print(uniqs)\n",
    "print(counts)\n",
    "\n",
    "C = 0.1\n",
    "clf = LinearSVC(C=C, random_state=SEED)\n",
    "ff = []\n",
    "\n",
    "for n in (range(17)):\n",
    "  y1_train = mc2(y_train, n)\n",
    "  y1_test = mc2(y_test, n)\n",
    "  clf.fit(X_train, y1_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  f1  = metrics.f1_score(y1_test, y_pred)\n",
    "  ff.append(f1)\n",
    "  print(n, counts[n], f1)\n",
    "\n",
    "print(ff)\n",
    "print(\"f1-macro:\", np.mean(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5294117647058824, 0.4, 0.7963176064441888, 0.7373572593800978, 0.4444444444444445, 0.688695652173913, 0.8326359832635983, 0.8847583643122676, 0.2666666666666667, 0.7692307692307693, 0.7333333333333334, 0.5263157894736842, 0.4, 0.7475247524752475, 0.8986486486486487, 0.7543859649122806]\n",
      "0.6506079374665639\n"
     ]
    }
   ],
   "source": [
    "print(ff)\n",
    "print(np.mean(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 92 69 23\n",
      "1 42 32 10\n",
      "2 1846 1384 462\n",
      "3 1400 1050 350\n",
      "4 30 23 7\n",
      "5 1354 1015 339\n",
      "6 1024 768 256\n",
      "7 1132 849 283\n",
      "8 50 37 13\n",
      "9 34 26 8\n",
      "10 360 270 90\n",
      "11 56 42 14\n",
      "12 16 12 4\n",
      "13 932 699 233\n",
      "14 1190 892 298\n",
      "15 284 213 71\n",
      "16 57032 42774 14258\n"
     ]
    }
   ],
   "source": [
    "### Сравнение классов\n",
    "\n",
    "for n in (range(17)):\n",
    "  y1_train = mc2(y_train, n)\n",
    "  y1_test = mc2(y_test, n)\n",
    "  n0 = np.unique(y, return_counts=True)[1][n]  \n",
    "  n1 = np.unique(y1_train, return_counts=True)[1][1]  \n",
    "  n2 = np.unique(y1_test, return_counts=True)[1][1]  \n",
    "  print(n, n0, n1, n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "(50155, 17)\n",
      "[16 16 16 ... 16 13 16]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 1]\n",
      "[50086    69]\n",
      "[0 1]\n",
      "[16696    23]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "classes = np.arange(17)\n",
    "print(classes)\n",
    "y2_train = label_binarize(y_train, classes)\n",
    "y2_test = label_binarize(y_test, classes)\n",
    "\n",
    "print(y2_train.shape)\n",
    "\n",
    "y20_train = y2_train[:, 0] \n",
    "y20_test = y2_test[:, 0] \n",
    "\n",
    "print(y_train)\n",
    "print(y20_train)\n",
    "print(y20_test)\n",
    "\n",
    "uniqs, counts = np.unique(y20_train, return_counts=True)\n",
    "print(uniqs)\n",
    "print(counts)\n",
    "uniqs, counts = np.unique(y20_test, return_counts=True)\n",
    "print(uniqs)\n",
    "print(counts)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1= 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "### y20 - первый бинарный класс\n",
    "C=0.1\n",
    "clf = LinearSVC(C=C, random_state=SEED)\n",
    "clf.fit(X_train, y20_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1  = metrics.f1_score(y20_test, y_pred)\n",
    "print(\"f1=\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03162278, 0.05623413, 0.1       , 0.17782794, 0.31622777])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-1.5, -0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.0s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   30.1s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 0 num= 92 C= 0.1 f1= 0.8636363636363636\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   26.7s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   26.5s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 1 num= 42 C= 0.1 f1= 0.5263157894736842\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   51.0s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   50.7s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 2 num= 1846 C= 0.1 f1= 0.8674698795180722\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   57.9s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   57.2s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 3 num= 1400 C= 0.1333521432163324 f1= 0.8035450516986705\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   27.4s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   26.6s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 4 num= 30 C= 0.1 f1= 0.6\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   59.3s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.0min finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 5 num= 1354 C= 0.1333521432163324 f1= 0.7758346581875994\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   38.6s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   37.7s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 6 num= 1024 C= 0.1 f1= 0.8825757575757577\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   40.3s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   40.5s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 7 num= 1132 C= 0.1 f1= 0.9314586994727592\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   29.4s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   28.5s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 8 num= 50 C= 0.1 f1= 0.608695652173913\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   27.2s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   26.6s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 9 num= 34 C= 0.1 f1= 0.75\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.5s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.2s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 10 num= 360 C= 0.1 f1= 0.7909604519774011\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.6s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.7s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 11 num= 56 C= 0.1 f1= 0.6206896551724138\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   27.0s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   28.0s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 12 num= 16 C= 0.1 f1= 0.6666666666666666\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   43.6s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   42.5s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 13 num= 932 C= 0.1 f1= 0.7948164146868251\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   36.0s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   36.1s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 14 num= 1190 C= 0.1 f1= 0.8950819672131146\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   34.1s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   34.3s finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 15 num= 284 C= 0.1 f1= 0.8513513513513514\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.6min finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.5min finished\n",
      "D:\\Bin\\Anaconda5\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class= 16 num= 57032 C= 0.1333521432163324 f1= 0.9920715308581607\n",
      "[0.8636363636363636, 0.5263157894736842, 0.8674698795180722, 0.8035450516986705, 0.6, 0.7758346581875994, 0.8825757575757577, 0.9314586994727592, 0.608695652173913, 0.75, 0.7909604519774011, 0.6206896551724138, 0.6666666666666666, 0.7948164146868251, 0.8950819672131146, 0.8513513513513514, 0.9920715308581607]\n",
      "f1-max= 0.7777158758625148\n",
      "Wall time: 31min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3. ######\n",
    "# Подбор гиперпараметра индивидуально для каждого класса\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "classes = np.arange(17)\n",
    "print(classes)\n",
    "y2_train = label_binarize(y_train, classes)\n",
    "y2_test = label_binarize(y_test, classes)\n",
    "\n",
    "uniqs, counts = np.unique(y, return_counts=True)\n",
    "ff = []\n",
    "\n",
    "for class1 in (range(17)):\n",
    "#for class1 in (range(1)):\n",
    "    \n",
    "# Бинарные классы\n",
    "  y21_train = y2_train[:, class1]\n",
    "  y21_test = y2_test[:, class1]\n",
    "\n",
    "# Определение оптимального С\n",
    "  model = model_selection.GridSearchCV(LinearSVC(penalty='l2', \n",
    "             multi_class='ovr', random_state=SEED), \n",
    "             {'C': np.logspace(-1, -0.5, 5)}, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)  \n",
    "  \n",
    "  model.fit(X_train, y21_train)  \n",
    "\n",
    "# Выделение С\n",
    "  rank = model.cv_results_['rank_test_score']\n",
    "  params = model.cv_results_['params']\n",
    "  i = np.argmin(rank)\n",
    "  C_model = params[i]['C']\n",
    "\n",
    "  model.fit(X_train, y21_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  f1  = metrics.f1_score(y21_test, y_pred)\n",
    "  ff.append(f1)\n",
    "  print('class=', class1, 'num=', counts[class1], 'C=', C_model, 'f1=', f1)\n",
    "\n",
    "# Итоговое определение f1-max\n",
    "print(ff)\n",
    "print('f1-max=', np.mean(ff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03162277660168379"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка\n",
    "rank = model.cv_results_['rank_test_score']\n",
    "params = model.cv_results_['params']\n",
    "i = np.argmin(rank)\n",
    "C_model = params[i]['C']\n",
    "C_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8636363636363636,\n",
       " 0.5263157894736842,\n",
       " 0.8674698795180722,\n",
       " 0.8035450516986705,\n",
       " 0.6,\n",
       " 0.7758346581875994,\n",
       " 0.8825757575757577,\n",
       " 0.9314586994727592,\n",
       " 0.608695652173913,\n",
       " 0.75,\n",
       " 0.7909604519774011,\n",
       " 0.6206896551724138,\n",
       " 0.6666666666666666,\n",
       " 0.7948164146868251,\n",
       " 0.8950819672131146,\n",
       " 0.8513513513513514,\n",
       " 0.9920715308581607]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
